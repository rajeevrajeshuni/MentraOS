import { MentraClient } from "../MentraClient";
import { AccountService } from "../services/AccountService";
import { resolve } from "path";
import * as fs from "fs";

const APP_PACKAGE_NAME = "isaiah.augmentos.livecaptions";

async function main() {
  const server = process.env.SERVER_URL || "https://isaiah.augmentos.cloud";
  const wsServer = server.replace(/^http/, "ws");
  const email = process.env.TEST_EMAIL || "user@example.com";
  const token =
    process.env.CORE_TOKEN ||
    AccountService.generateTestAccount(email).coreToken;

  console.log("üéØ End-to-End LiveKit Audio Test");
  console.log("================================");
  console.log("Server:", server);
  console.log("Email:", email);
  console.log();

  const client = new MentraClient({
    email,
    serverUrl: `${wsServer}`,
    coreToken: token,
    behavior: {
      disableStatusUpdates: true,
      useLiveKitAudio: true, // Enable LiveKit audio transport
    },
    debug: { logLevel: "info", logWebSocketMessages: false },
  });

  let transcriptionReceived = false;

  client.on("connection_ack", (data) => {
    console.log("‚úÖ CONNECTION_ACK received");
    if (data.livekit) {
      console.log("   LiveKit URL:", data.livekit.url);
      console.log("   Room:", data.livekit.roomName);
    }
  });

  client.on("livekit_connected", () => {
    console.log("‚úÖ LiveKit connected to Go bridge");
  });

  // Listen for transcription events
  client.on("display_event", (event) => {
    console.log("üìù DISPLAY_EVENT received", event);
    if (event.packageName === APP_PACKAGE_NAME) {
      const text =
        event.layout.topText ||
        event.layout.bottomText ||
        event.layout.text ||
        "";
      if (text && text.trim()) {
        console.log("üìù TRANSCRIPTION:", text);
        transcriptionReceived = true;
      }
    }
  });

  client.on("error", (error) => {
    console.error("‚ùå Error:", error);
  });

  // Connect to server
  console.log("1Ô∏è‚É£  Connecting to server...");
  await client.connect();

  // Wait for LiveKit
  console.log("2Ô∏è‚É£  Waiting for LiveKit connection...");
  // Give bridge + room some time to fully establish
  await new Promise((resolve) => setTimeout(resolve, 3000));

  // Install and start transcription app
  console.log("3Ô∏è‚É£  Setting up Live Captions app...");
  try {
    await client.installApp(APP_PACKAGE_NAME);
    console.log("App installed");
  } catch (e) {
    console.log("App already installed", e);
  }

  try {
    await client.stopApp(APP_PACKAGE_NAME);
  } catch {
    // ignore.
  }

  await client.startApp(APP_PACKAGE_NAME);
  console.log("   ‚úÖ App started");

  // Send audio file with VAD signaling (lets cloud authorize and process speech)
  console.log("4Ô∏è‚É£  Sending audio file via LiveKit bridge...");
  const wavPath = resolve(__dirname, "../audio/short-test-16khz.wav");

  if (!fs.existsSync(wavPath)) {
    console.error("‚ùå Audio file not found:", wavPath);
    process.exit(1);
  }

  // Stream via client helper which sets VAD on/off and streams at proper cadence
  // Stream file (client should route to Go bridge when useLiveKitAudio=true)
  await client.startSpeakingFromFile(wavPath, true);
  console.log("   ‚úÖ Audio streaming triggered");

  // Wait for transcriptions
  console.log("5Ô∏è‚É£  Waiting up to 60s for transcriptions...");
  // Keep the session active for a minute to allow server to process and apps to emit events
  const deadline = Date.now() + 60_000;
  while (Date.now() < deadline) {
    if (transcriptionReceived) break;
    await new Promise((resolve) => setTimeout(resolve, 1000));
  }

  // Results
  console.log();
  console.log("üìä Results");
  console.log("==========");
  if (transcriptionReceived) {
    console.log("‚úÖ Transcription received successfully!");
    console.log("‚úÖ End-to-end LiveKit audio flow is working!");
  } else {
    console.log("‚ö†Ô∏è  No transcriptions received");
    console.log("   This could mean:");
    console.log("   - The transcription service is not running");
    console.log("   - Audio is not flowing through LiveKit properly");
    console.log("   - The app is not subscribed to audio events");
  }

  // Keep connection briefly to flush any final events, then disconnect
  await new Promise((resolve) => setTimeout(resolve, 1000));
  await client.disconnect();
  process.exit(transcriptionReceived ? 0 : 1);
}

main().catch((err) => {
  console.error("Test failed:", err);
  process.exit(1);
});
